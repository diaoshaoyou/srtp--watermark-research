### 【注：红色字体表示了可能优化的地方】

## To do list

- 能不能借用实验室的资源跑算法（gpu）
  - 用我们自己的图像集跑一下算法看结果
  - 增加图像的张数看效果
  
- **<font color='red'>【DDL：11月1日20:30】</font>**
  
  - 看论文[9] -> closed form matting
  - 最小二乘法 -> 求c
  - 看懂solve images函数
- 论文和代码的对应关系表格整理
  
- 整理我们的问题，制作ppt或word文档，发给黎叔看

- 实现算法的部分优化

- 制作中期答辩ppt

  

## 补充知识

### 梯度

- 图像梯度是指图像某像素在x和y两个方向上的变化率（与相邻像素比较），是一个二维向量，由2个分量组成，X轴的变化、Y轴的变化 。

- 我们即可以求出梯度向量的模和角度

  ![[公式]](https://www.zhihu.com/equation?tex=M_%7B2%7D%28x%2Cy%29%3D%5Csqrt%7Bg_%7Bx%7D%5E2+%2B+g_%7By%7D%5E2%7D)

  ![[公式]](https://www.zhihu.com/equation?tex=M_%7B1%7D%28x%2Cy%29%3D%7Cg_%7Bx%7D%7C+%2B+%7Cg_%7By%7D%7C+)

  ![[公式]](https://www.zhihu.com/equation?tex=M_%7B%5Cinfty%7D%28x%2Cy%29%3DMax%5C%7B%7Cg_%7Bx%7D%7C+%2C+%7Cg_%7By%7D%7C%5C%7D)

  ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha+%28x%2Cy%29+%3D+tan%5E%7B-1%7D%5Cleft%5B+%5Cfrac%7Bg_%7By%7D%7D%7Bg_%7Bx%7D%7D+%5Cright%5D)

  模值也可以用 ![[公式]](https://www.zhihu.com/equation?tex=L_%7B1%7D) 或者![[公式]](https://www.zhihu.com/equation?tex=L_%7B%5Cinfty%7D) 范数来估计，在计算机实现上更为容易

  ![img](https://pic1.zhimg.com/80/v2-5b469c9adbf41cbd75f635b219d240fc_720w.jpg)

  梯度向量的几何意义如上图所示，模表示变化的剧烈程度，角度描述边缘的法线方向





## estimate_watermark.py

#### 估算水印梯度grad(W)

- ```python
  def estimate_watermark(foldername)
  ```

  - 估算水印的梯度 grad(W) = median(grad(J))
  - **返回值**
    - **gx**
    - **gy**
    - **gxlist**
    - **gylist**



#### 标准化图像

- ```python
  def PlotImage(image)
  ```

  - 将image转换为float类型，标准化到0-1之间



#### 二值化？

- ```python
  def image_threshold(image, threshold=0.5)
  ```
  - 像素值大于等于threshold*MAX的像素点置为1
  - <font color='red'>我们是否能改进这个函数？</font>



#### 裁剪水印

- ```python
  def crop_watermark(gradx, grady, threshold=0.4, boundary_size=2)
  ```

  - 输入的是grad(W)（水印的梯度gx，gy）
  - 计算梯度的模 W_mod = np.sqrt(np.square(gradx) + np.square(grady))
    - <font color='red'>如果图像很大，是否考虑用|gradx|+|grady|代题平方根以减少计算量？</font>
  - 调用***PlotImage***
  - 调用***image_threshold***
  - <font color='red'>裁剪效果不太好，保留了大块的无关区域，我们能否改进二值化算法？</font>
    - <img src="C:\Users\Doris Cullen\AppData\Roaming\Typora\typora-user-images\image-20201025152046702.png" alt="image-20201025152046702" style="zoom:50%;" />
  - **返回值**
    - **cropped_gx**
    - **cropped_gy**



#### 泊松重建 -> 粗略的水印（重建的是彩色图像？）

- ```python
  def poisson_reconstruct(gradx, grady, kernel_size=KERNEL_SIZE, num_iters=100, h=0.1, boundary_image=None, boundary_zero=True)
  ```

  - 从grad(W)重建出水印图像

  - <font color='red'>boundary_zero有啥用？可以考虑删掉？</font>

  - 首先计算laplacian，然后从一张噪声图逐步重建水印图像

  - ![image-20201025153156571](C:\Users\Doris Cullen\AppData\Roaming\Typora\typora-user-images\image-20201025153156571.png)

    - 图像中的边缘就是那些灰度值发生跳变的区域，拉普拉斯算子可以用二次微分正峰和负峰之间的0点确定边缘线的位置，因此可以突出图像中的孤立点、孤立线等。通梯度算子一样，拉普拉斯算子也会增强图像中的噪声，有时用拉普拉斯算子进行边缘检测时，可以将图像先进行平滑处理
      - 不过这里好像不是边缘检测？

  - 最后得到的loss还是挺大的，<font color='red'>有没有更好的方法求解泊松重建方程？或者增加迭代的轮数num_iters，修改参数h有没有效果？这里loss大对后面的影响大不大？</font>

    ```
    loss 99  =  42.12282793304221
    ```

  - <font color='red'>这里的error/loss值是否能用于评估图像的差别（去水印效果的好坏）</font>

  - **返回值**

    - **W_m**

    

- ```python
  def poisson_reconstruct2(gradx, grady, boundarysrc)
  ```

  - <font color='red'>也可以用它运行试一试</font>



#### 检测水印在图像中的位置

- ```python
  def watermark_detector(img, gx, gy, thresh_low=200, thresh_high=220, printval=False)
  ```

  - Wm = (np.average(np.sqrt(np.square(gx) + np.square(gy)), axis=2))
  - 用canny计算edgemap
  - 计算倒角距离
  - 找出了倒角距离最大的点
  - <font color='red'>倒角距离到底是个啥？这里是不是一种图像匹配算法？</font>
  - **返回值**
    - **im：画了矩形的图像**
    - **start：矩形左上角的坐标**
    - **end：矩形的长度**
      - <font color='red'>这个变量命名为end不合理，可以考虑修改其他代码（反正用的时候大多是start+end用的，直接加起来就挺好），或者把end变量名改为length</font>



## watermark_reconstruct.py

#### 裁剪图像

- ```python
  def get_cropped_images(foldername, num_images, start, end, shape)
  ```

  - **返回值**
    - **J：裁剪后的带水印图像，有4维，[index, , ,]**
    - **img_paths：图像的路径**



#### 一些疑问

- <font color='red'>**get a random subset of J** 干啥用的？代码好像没有用到？</font>
- <font color='red'>**Wm = W_m - W_m.min()**的作用？</font>



#### 估计α

- ```python
  def estimate_normalized_alpha(J, W_m, num_images=11, threshold=170, invert=False, adaptive=False, adaptive_threshold=21, c2=10)
  ```
  - np.stack
  - <font color='red'>iterpatch有什么用？</font>
  - 调用closed_form_matting.py中的函数



#### 估计blend factor

- ```python
  def estimate_blend_factor(J, W_m, alph, threshold=0.01*255)
  ```

  - 【参照论文中的3.2节：Matte and Blend Factor Initialization】
  - 论文中的依据：Jk = E(Wm) + c · αn · E[Ik]
  - 首先Jm = J - W_m
    - W_m与J维度不同，进行维度扩展再相减
  - E[I] = α * median(J, axis=0)
  - c = sum(梯度J * 梯度I) / sum(梯度I^2) / K
    - <font color='red'>论文中好像说用最小二乘法？</font>



## closed_form_matting.py

主要思路：来自参考文献[9]《A Closed-Form Solution to Natural Image Matting》

主要作用：估计出$\alpha_{n}$  

背景知识：将一张图分为前景**F**(所要抠的水印部分)、后景**B**(非水印)、未知区域(水印非水印交界处)

**w**是一个很小的窗口(如3*3的矩阵)，以某个像素点为中心，所以一个**w**对应一个像素点。

在**w**内每个像素点处$F_{i}$间差距小，$B_{i}$间差距小，故当做常量。



### $\alpha_{n}$简介

- $\alpha_{n}$是只能取0或1的矩阵，取1的像素点表示水印所在，取0表示非水印。对每一个像素点$I_{i}$则有：

	$I_{i}=\alpha_{ni}F_{i}+(1-\alpha_{ni})B_{i}——(1)$    

	$F_{i}$表示前景像素点(水印部分)，$B_{i}$表示背景像素点(非水印)，$\alpha_{ni}$表示每个像素点的$\alpha_{n}$ 



- （1）线性变换后，在一个小窗口w内，$\alpha_{ni}$的估计值为：

	$\alpha_{ni}=aI_{i}+b——(2)$               其中$a=\frac{1}{F-B}$，$b=-\frac{B}{F-B}$ 



- 由上式我们可以构造一个cost function $J(\alpha_{n},a,b)$，是J取最小值的$\alpha$就是最好的估计值。



### $J(\alpha_{n},a,b)$ 

- $J=\sum\limits_{j\in I}(\sum\limits_{i\in w_{j}}(\alpha_{ni}-a_{j}I_{i}-b_{j}+\epsilon a_{j}^{2})^{2})$  ，下面简述其由来。

- 在一个w中，设每个像素点的实际值为$\alpha_{ni}$，估计值为$a_{j}I_{i}+b_{j}$ ，j是$w_{j}$中的中心像素点。故

	$\sum\limits_{i\in w_{j}}(\alpha_{ni}-a_{j}I_{i}-b_{j})^{2}$          就是$w_{j}$内每个像素点估计偏差的平方和，也相当于**一个像素j的估计偏差**

- 把图像$I$中所有像素j的估计偏差求和：

	$\sum\limits_{j\in I}(\sum\limits_{i\in w_{j}}(\alpha_{ni}-a_{j}I_{i}-b_{j})^{2})$   

- 最后加点平滑用的参数：

	$J=\sum\limits_{j\in I}(\sum\limits_{i\in w_{j}}(\alpha_{ni}-a_{j}I_{i}-b_{j}+\epsilon a_{j}^{2})^{2})$   

### J求最值

- $\alpha_{ni}$不变，以a、b为变量求$J$的最小值。把求得a、b的取值代回$J$得：

	$J=\sum\limits_{k\in I}(\alpha_{k}^{T}G_{k}^{T}G_{k}\alpha_{k})=\sum\limits_{k\in I}(\alpha_{k}^{T}L\alpha_{k})$      此处L就是拉普拉斯矩阵

```python
L = computeLaplacian(img)
```



- 再求$J$最小值，相当于求$Loss=\alpha^{T}L\alpha+\lambda(\alpha^{T}-b_{s}^{T}D_{s}(\alpha-b_{s})$ 的最小值。

	$D_{s}$是对角矩阵，对角元素是图中每个像素点。B或F处取1，未知区域取0

	$b_{s}$是和$\alpha_{n}$等大的列向量，B或F处取$\alpha_{ni}$的值，未知区域取0。

```python
consts_map = (np.sum(abs(img-scribbled_img),axis=-1)>0.001).astype(np.float64)
#consts_map：水印和非水印区像素=1，不确定区=0
consts_vals = scribbled_img[:,:,0]*consts_map
D_s = consts_map.ravel()#ravel()把多维数组转换成一维数组W*h
b_s = consts_vals.ravel()
sD_s = scipy.sparse.diags(D_s)#sD_s才是文章中的Ds
```



- 求个导可得：

	$(L+\lambda D_{s})\alpha_{n}=\lambda b_{s}$ 

```python
x = scipy.sparse.linalg.spsolve(L + mylambda*sD_s, mylambda*b_s)
```

