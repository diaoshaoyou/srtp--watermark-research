# 论文笔记

## 大体步骤

1、从一系列图中抽象图片结构，**estimate** watermark  

2、**detect** watermark region  

3、**separate** watermark into image + alpha matte  

4、**reconstruct** background image  

## 背景知识

梯度：对每个分量求偏导再乘以其单位方向向量，最后相加

Chamfer distance



## 结论

水印位置、颜色、不透明度都不会影响，水印空间变形会影响

## 数学原理

I是原图，W是水印，J是有水印图，$\alpha$ 是不透明度，现在共有K张J，则

==J~k~ = $\alpha$W+(1-$\alpha$)I~k~   k=1,2……K                                  (1)== 

#### estimate

对每张图 J 求梯度，再求K张图梯度的中位数。K越大，$W_{m}$ 越接近$\alpha W$,$W_{m}$是理论值，$\widehat{W}_{m}$是实际值

$\triangledown \widehat{W}_{m}=median_{k}(\triangledown J_{k})$                                      (2)

由(2)可得，(并未搞懂数学运算)

$E[\triangledown J_{k}]=E[\triangledown W_{m}]+E[\triangledown I_{k}]-E[\triangledown(\alpha I_{k})]$    

$=\triangledown W_{m}+E[\triangledown I_{k}]-\triangledown \alpha E[I_{k}]-\alpha E[\triangledown I_{k}]$  

$=\triangledown W_{m}-\triangledown \alpha E[I_{k}]$                                               (3)

#### matting and reconstruction

==arg min$\sum_{k}[E_{data}(W,\alpha,I_{k})+\lambda_{I}E_{reg}(\triangledown I_{k})] + \lambda_{\omega}E_{reg}(\triangledown W)+\lambda_{\alpha}E_{reg}(\triangledown \alpha)+\beta E_{f}(\triangledown (\alpha W))$   (4)== 

其中：($\epsilon=0.001$)

（i）$E_{data}(I_{k},W,\alpha)=\sum{ \sqrt{ \epsilon^{2}+|\alpha W+(1-\alpha)I_{k}-J_{k}|^{2} }}$  ，用来弥补(1)式带来的偏差  

（ii）$E_{reg}$ 是正则项(regularization term)，用来使水印和重构的图片局部光滑  

 	 	$E_{reg}(\triangledown I)=\sum{\sqrt{\epsilon ^{2}+|\alpha_{x}|I_{x}^{2}+|\alpha_{y}|I_{y}^{2}}}$   

  		$E_{reg}(\triangledown W)=\sum{\sqrt{\epsilon ^{2}+|\alpha_{x}|W_{x}^{2}+|\alpha_{y}|W_{y}^{2}}}$   

  		$E_{reg}(\triangledown \alpha)=\sum{\sqrt{\epsilon ^{2}+\alpha_{x}^{2}+\alpha_{y}^{2}}}$    

（iii）$E_{f}$ 是扩展项(fidelity term)，仅有前面两项还不够，扩展项弥补了$\triangledown W_{m}$ 和$\triangledown \widehat{W}_{m}$ 之间的差距

​		  $E_{f}(\triangledown W_{m})=\sum{\sqrt{\epsilon^{2}+\| \triangledown W_{m}-\triangledown \widehat{W}_{m} \|^{2}}}$  （有无该扩展项：fig.4(d)上下2图对比明显）

#### optimization

(4)式中未知数过多，故引入附加变量$W_{k}$，表示第k张图的水印，每个$W_{k}$都很接近W  

arg min$\sum_{k}E_{data}(W_{k},\alpha,I_{k})+\lambda_{I}E_{reg}(\triangledown I_{k}) + \lambda_{\omega}E_{reg}(\triangledown W_{k})+\lambda_{\alpha}E_{reg}(\triangledown \alpha)+\beta E_{f}(\triangledown (\alpha W_{k}))+\gamma E_{aux}(W,W_{k})$——(5)

其中$E_{aux}(W,W_{k})=\sum{|W-W_{k}|}$ 

（i）**先假定$\alpha$和$W$不变**，则变成：

==arg min$\sum E_{data}(I_{k},W_{k})+\lambda_{I}E_{reg}(\triangledown I_{k})+\lambda_{\omega}E_{reg}(\triangledown W_{k})+\beta E_{f}(\triangledown (\alpha W_{k}))+\gamma E_{aux}(W,W_{k})$  (6)== 

（ii）**解决W**：要使(6)和式最小，则要使每一项的$E_{aux}$最小，则取$W=median_{k}W_{k}$ 		   

（iii）**解决$\alpha$**：$\alpha = c\alpha_{n}$，其中c是常数blending factor，$\alpha_{n}$是标准化的matte

#### generalized model 



